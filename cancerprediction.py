# -*- coding: utf-8 -*-
"""CancerPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z4o2ZJfIltE1S8gyjBGjm0TvXV3lNoHb
"""

import pandas as pd
df  = pd.read_csv('kag_risk_factors_cervical_cancer.csv',header = 0, na_values='?')
df.head()

null_counts = df.isnull().sum()
null_counts

df = df.drop(['STDs: Time since first diagnosis', 'STDs: Time since last diagnosis'], axis=1)
df.head()

null_counts = df.isnull().sum()
null_counts

df = df.astype('float')
df.dtypes

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
for col in df.columns:
  df[col] = scaler.fit_transform(df[[col]])

null_counts = df.isnull().sum()
null_counts

columns_to_replace = ['Number of sexual partners' ,	'First sexual intercourse',	'Num of pregnancies',	'Smokes',	'Smokes (years)',	'Smokes (packs/year)']
# replace null values in a particular column with mode
for cols in columns_to_replace:
  df[cols].fillna(df[cols].mode()[0], inplace=True)

null_counts = df.isnull().sum()
null_counts

from sklearn.impute import KNNImputer

# create an imputer object with the chosen imputation strategy
imputer = KNNImputer(n_neighbors=3)

# impute missing values in the DataFrame
df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)

null_count = df.isnull().sum()
null_count

outlier_columns = ['Age','Number of sexual partners','First sexual intercourse','Num of pregnancies','Smokes','Smokes (years)','Smokes (packs/year)','Hormonal Contraceptives','Hormonal Contraceptives (years)','IUD','IUD (years)','STDs','STDs (number)','STDs:condylomatosis','STDs:cervical condylomatosis','STDs:vaginal condylomatosis','STDs:vulvo-perineal condylomatosis','STDs:syphilis','STDs:pelvic inflammatory disease','STDs:genital herpes','STDs:molluscum contagiosum','STDs:AIDS','STDs:HIV','STDs:Hepatitis B','STDs:HPV','STDs: Number of diagnosis','Dx:Cancer','Dx:CIN','Dx:HPV','Dx']
from scipy import stats
z_scores = df.apply(lambda x: (x - x.mean()) / x.std())
outlier_threshold = 3
df = df[(z_scores <= outlier_threshold) | (z_scores >= -outlier_threshold)]

num_outliers = ((z_scores > outlier_threshold) | (z_scores < -outlier_threshold)).sum()
print('Number of outliers in each column:')
for col_name, num in num_outliers.iteritems():
    print(f"{col_name}: {num}")

null_counts = df.isnull().sum()
null_counts

df = df.drop(['STDs:cervical condylomatosis', 'STDs:AIDS'], axis=1)
df.isnull().sum()

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

test1 = df.copy()
test1 = test1.drop(['Hinselmann','Biopsy','Citology'],axis=1)
X = test1.drop('Schiller', axis=1)
y = test1['Schiller']

smote = SMOTE(random_state=40)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
X_train_resampled,y_train_resampled = smote.fit_resample(X,y)
pca = PCA(n_components=26)
X_train_pca = pca.fit_transform(X_train_resampled)

# Train SVM
svm_model = SVC()
svm_model.fit(X_train_pca, y_train_resampled)

X_test_pca = pca.transform(X_test)
svm_preds = svm_model.predict(X_test_pca)

# Calculate accuracy, precision, and recall for SVM
svm_accuracy = accuracy_score(y_test, svm_preds)
svm_precision = precision_score(y_test, svm_preds,average="weighted")
svm_recall = recall_score(y_test, svm_preds)

# Results
from tabulate import tabulate

table = [["", "Accuracy", "Precision", "Recall"],
         ["SVM", "{:.4f}".format(svm_accuracy), "{:.4f}".format(svm_precision), "{:.4f}".format(svm_recall)]]

print(tabulate(table, headers="firstrow", tablefmt="fancy_grid"))